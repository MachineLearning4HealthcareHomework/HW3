{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(36)\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, MaxPooling2D, GlobalMaxPool2D, Conv2D, Conv2DTranspose,concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size, batchnorm, activation):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "def get_unet(input_img, n_filters, dropout, batchnorm, kernel_size, activation, depth):\n",
    "    # Contracting Path\n",
    "    c=[None]*(depth+3)\n",
    "    #form 0(=init) to depth(=last decode), also bottom added as depth[depth+1]\n",
    "    p=[input_img]*(depth+2)\n",
    "    #Encode\n",
    "    for current_depth in range(depth):\n",
    "        current_depth+=1\n",
    "        c[current_depth]=conv2d_block(p[current_depth-1], n_filters * pow(2,current_depth-1), kernel_size, batchnorm, activation)\n",
    "        p[current_depth]=MaxPooling2D((2,2))(c[current_depth])\n",
    "        p[current_depth]=Dropout(dropout)(p[current_depth])\n",
    "    #Bottom\n",
    "    c[depth+1]=conv2d_block(p[depth],n_filters* pow(2,depth),kernel_size,batchnorm, activation)\n",
    "        \n",
    "    #Decode\n",
    "    u=[None]*(depth+2)\n",
    "    d=[c[depth+1]]*(depth+2)\n",
    "    for current_depth in reversed(range(depth)):\n",
    "        u[current_depth] = Conv2DTranspose(n_filters * pow(2,current_depth), (kernel_size, kernel_size), strides = (2, 2), padding = 'same')(d[current_depth+1])\n",
    "        u[current_depth] = concatenate([u[current_depth], c[current_depth+1]])\n",
    "        u[current_depth] = Dropout(dropout)(u[current_depth])\n",
    "        d[current_depth] = conv2d_block(u[current_depth], n_filters * pow(2,current_depth), kernel_size, batchnorm, activation)\n",
    "\n",
    "    #decision\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(d[0])\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    #new\n",
    "    model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.save('models/'+string+'.h5')\n",
    "    plot_model(model, to_file='diagrams/'+string+'.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "im_height=256\n",
    "im_width=256\n",
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "#mode = get_unet(input_img, n_filter, dropout, Batchnormalization, convolution window size, activation function, depth)\n",
    "#standard ->unet(input_img, 16, 0.05,True,3,'relu', 4)\n",
    "filters=[8,16,32]\n",
    "dropouts=[5,25,50]\n",
    "window_sizes=[3,5]\n",
    "activations=['relu','selu','tanh','sigmoid']\n",
    "depths=[3,5]\n",
    "for föuter in filters:\n",
    "    for dropout in dropouts:\n",
    "        for window_size in window_sizes:\n",
    "            for activation in activations:\n",
    "                for depth in depths:\n",
    "                    string=str(föuter)+'F'+str(dropout)+'Dr'+str(window_size)+'Ws'+activation[:2]+'A'+str(depth)+'D'\n",
    "                    model = get_unet(input_img, föuter, dropout/100, True, window_size, activation, depth)\n",
    "                    model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "                    plot_model(model, to_file='diagrams/'+string+'.png')\n",
    "                    model.save('models'+str(depth)+'/'+string+'.h5')\n",
    "                    print('Done with: '+string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n",
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images_path='project3_data/data/train_images'\n",
    "train_labels_path='project3_data/data/train_labels'\n",
    "\n",
    "for file in os.listdir(train_images_path):\n",
    "    images=np.load(train_images_path+'/'+file)\n",
    "    labels=np.load(train_labels_path+'/'+file)\n",
    "    overall_depth=images.shape[0]\n",
    "    for curr_depth in range(overall_depth):\n",
    "        train_images=np.expand_dims(images[curr_depth],axis=2)\n",
    "        train_labels=np.expand_dims(labels[curr_depth], axis=2)\n",
    "        \n",
    "X=np.array(train_images)\n",
    "print(X.shape)\n",
    "Y=np.array(train_labels)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24e93b5cfa4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdepths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0mstring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mföuter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Dr'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Ws'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mföuter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Painted model: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_unet' is not defined"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "filters=[16,32]\n",
    "dropouts=[20,50]\n",
    "window_sizes=[3,5]\n",
    "activations=['relu']\n",
    "depths=[3,5]\n",
    "strings=[]\n",
    "validation_scores=[]\n",
    "test_scores=[]\n",
    "for föuter in filters:\n",
    "    for dropout in dropouts:\n",
    "        for window_size in window_sizes:\n",
    "            for activation in activations:\n",
    "                for depth in depths:\n",
    "                    string=str(föuter)+'F'+str(dropout)+'Dr'+str(window_size)+'Ws'+activation[:2]+'A'+str(depth)+'D'\n",
    "                    model = get_unet(Input((256, 256, 1), name='img'), föuter, dropout/100, True, window_size, activation, depth)\n",
    "                    print('Painted model: '+string)\n",
    "                    model.fit(X,Y)\n",
    "                    validationY=model.predict(validationX)\n",
    "                    validation_scores.append(scoring(validationY,validation_labels))\n",
    "                    strings.append(string)\n",
    "                    testY=model.predict(testX)\n",
    "                    print(scoring(testY,test_labels))\n",
    "                    print('Done model: '+string)\n",
    "lowest_index=validation_scores.index(min(validation_scores))\n",
    "print('Best Model: '+strings[lowest_index])\n",
    "best_model=keras.models.load('models/'+strings[lowest_index]+'.h5')\n",
    "best_model.fit(X100,Y100)\n",
    "testY=best_model.predict(testX)\n",
    "print(scoring(testy,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
