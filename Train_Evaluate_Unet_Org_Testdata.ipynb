{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on non-rotated test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect non-rotated test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './data_new/data/test_images/'\n",
    "label_dir = './data_new/data/test_labels/'\n",
    "test_images = {}\n",
    "test_labels = {}\n",
    "\n",
    "filenames = []\n",
    "for dirs, subdirs, files in os.walk(test_dir):\n",
    "    for name in files:\n",
    "        filenames.append(name)\n",
    "        path_to_use = os.path.join(dirs, name)\n",
    "        if path_to_use.endswith('.npy'):\n",
    "            test_images[name]=np.load(path_to_use)\n",
    "            test_labels[name]=np.load(os.path.join(label_dir, name))\n",
    "            print(f\"file: {name}, shape: {test_images[name].shape}, classes: {np.unique(test_labels[name])}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 0\n",
    "for name in filenames:\n",
    "    num_images += test_images[name].shape[0]\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude sample-52.npy due to higher image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros([num_images-21, 256, 256], dtype=np.float32)\n",
    "Y_test = np.zeros([num_images-21, 256, 256], dtype=np.int8)\n",
    "\n",
    "ind = 0\n",
    "for name in filenames:\n",
    "    for i in range (0, test_images[name].shape[0]):\n",
    "        if test_images[name].shape[1] != 256:\n",
    "            continue\n",
    "                  \n",
    "        X_test[ind] = test_images[name][i]\n",
    "        Y_test[ind] = test_labels[name][i]\n",
    "            \n",
    "        ind = ind + 1\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "for i in range (0, 22):\n",
    "    plt.subplot(22, 2, 2*i+1)\n",
    "    plt.imshow(X_test[i,:,:])#, cmap=\"bone\", origin=\"lower\"\n",
    "    plt.subplot(22, 2, 2*i+2)\n",
    "    plt.imshow(Y_test[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    denominator = np.amax(image)\n",
    "    return image/denominator\n",
    "\n",
    "print(\"Range of input values: %s\" % {np.amin(X_test), np.amax(X_test)})\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i] = normalize(X_test[i])\n",
    "    \n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(\"Normalized range of input values: %s\" % {np.amin(X_test), np.amax(X_test)})\n",
    "print(\"Normalized input image shape: %s\" % (X_test.shape,))\n",
    "print(\"Normalized image dtype: %s\" % (X_test.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "for i in range (0, 22):\n",
    "    plt.subplot(22, 2, 2*i+1)\n",
    "    plt.imshow(X_test[i,:,:,0])#, cmap=\"bone\", origin=\"lower\"\n",
    "    plt.subplot(22, 2, 2*i+2)\n",
    "    plt.imshow(Y_test[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the labels to categorical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_vec = np.reshape(Y_test, [Y_test.shape[0], Y_test.shape[1]*Y_test.shape[2]])\n",
    "print(\"Vectorized new label shape: %s\" % (Y_test_vec.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predicted labels from the best model after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_net = tf.keras.models.load_model('U_net_32F25Dr3WsreA5D')\n",
    "U_net.load_weights(\"U_net_32F25Dr3WsreA5D.h5\")\n",
    "\n",
    "Y_pred = U_net.predict(X_test)\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "print(\"New predicted labels shape: %s \" % (Y_pred.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    results=[]\n",
    "    y_true=y_true.flatten()\n",
    "    y_pred=y_pred.flatten()\n",
    "    #Overall precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "    #Per-class precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='macro'))\n",
    "    #jaccard (right average?)\n",
    "    results.append(metrics.jaccard_score(y_true, y_pred, average='macro'))\n",
    "    return results\n",
    "get_scores(Y_test_vec, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    results=[]\n",
    "    y_true=y_true.flatten()\n",
    "    y_pred=y_pred.flatten()\n",
    "    #Overall precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "    #Per-class precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='weighted'))\n",
    "    #jaccard (right average?)\n",
    "    results.append(metrics.jaccard_score(y_true, y_pred, average='weighted'))\n",
    "    return results\n",
    "get_scores(Y_test_vec, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape back to original dimensions\n",
    "Y_pred_org = np.reshape(Y_pred, [Y_pred.shape[0], 256, 256])\n",
    "print(Y_pred_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_pred_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Y_test[ind])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Y_pred_org[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2]\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=Y_test_vec.flatten(), predictions=Y_pred.flatten()).numpy()\n",
    "\n",
    "# Normalization of Confusion Matrix to the interpretation of which class is being misclassified.\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    " \n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
    "\n",
    "# plot confusion matrix\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on rotated test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_rot = './data_new/data/test_images_randomly_rotated/'\n",
    "label_dir_rot = './data_new/data/test_labels_randomly_rotated/'\n",
    "test_images_rot = {}\n",
    "test_labels_rot = {}\n",
    "\n",
    "filenames_rot = []\n",
    "for dirs, subdirs, files in os.walk(test_dir_rot):\n",
    "    for name in files:\n",
    "        filenames_rot.append(name)\n",
    "        path_to_use = os.path.join(dirs, name)\n",
    "        if path_to_use.endswith('.npy'):\n",
    "            test_images_rot[name]=np.load(path_to_use)\n",
    "            test_labels_rot[name]=np.load(os.path.join(label_dir_rot, name))\n",
    "            print(f\"file: {name}, shape: {test_images_rot[name].shape}, classes: {np.unique(test_labels_rot[name])}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat label 3 as label 1 in sample-53 and sample-54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_rot['sample-53.npy'][test_labels_rot['sample-53.npy']==3] = 1\n",
    "test_labels_rot['sample-54.npy'][test_labels_rot['sample-54.npy']==3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in filenames_rot:\n",
    "    print(f\"file: {name}, shape: {test_images_rot[name].shape}, classes: {np.unique(test_labels_rot[name])}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_rot = 0\n",
    "for name in filenames_rot:\n",
    "    num_images_rot += test_images_rot[name].shape[0]\n",
    "print(num_images_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rot = np.zeros([num_images_rot, 256, 256], dtype=np.float32)\n",
    "Y_test_rot = np.zeros([num_images_rot, 256, 256], dtype=np.int8)\n",
    "\n",
    "ind = 0\n",
    "for name in filenames_rot:\n",
    "    for i in range (0, test_images_rot[name].shape[0]):\n",
    "                   \n",
    "        X_test_rot[ind] = test_images_rot[name][i]\n",
    "        Y_test_rot[ind] = test_labels_rot[name][i]\n",
    "            \n",
    "        ind = ind + 1\n",
    "print(X_test_rot.shape, Y_test_rot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "for i in range (0, 22):\n",
    "    plt.subplot(22, 2, 2*i+1)\n",
    "    plt.imshow(X_test_rot[i,:,:])\n",
    "    plt.subplot(22, 2, 2*i+2)\n",
    "    plt.imshow(Y_test_rot[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    denominator = np.amax(image)\n",
    "    return image/denominator\n",
    "\n",
    "print(\"Range of input values: %s\" % {np.amin(X_test_rot), np.amax(X_test_rot)})\n",
    "\n",
    "X_test_rot = X_test_rot.astype('float32')\n",
    "\n",
    "for i in range(X_test_rot.shape[0]):\n",
    "    X_test_rot[i] = normalize(X_test_rot[i])\n",
    "    \n",
    "X_test_rot = X_test_rot[..., np.newaxis]\n",
    "\n",
    "print(\"Normalized range of input values: %s\" % {np.amin(X_test_rot), np.amax(X_test_rot)})\n",
    "print(\"Normalized input image shape: %s\" % (X_test_rot.shape,))\n",
    "print(\"Normalized image dtype: %s\" % (X_test_rot.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "for i in range (0, 22):\n",
    "    plt.subplot(22, 2, 2*i+1)\n",
    "    plt.imshow(X_test_rot[i,:,:,0])\n",
    "    plt.subplot(22, 2, 2*i+2)\n",
    "    plt.imshow(Y_test_rot[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the labels to categorical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_rot_vec = np.reshape(Y_test_rot, [Y_test_rot.shape[0], Y_test_rot.shape[1]*Y_test_rot.shape[2]])\n",
    "print(\"Vectorized new label shape: %s\" % (Y_test_rot_vec.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_net = tf.keras.models.load_model('U_net_32F25Dr3WsreA5D')\n",
    "U_net.load_weights(\"U_net_32F25Dr3WsreA5D.h5\")\n",
    "\n",
    "Y_pred_rot = U_net.predict(X_test_rot)\n",
    "Y_pred_rot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_rot = np.argmax(Y_pred_rot, axis=-1)\n",
    "print(\"New predicted labels shape: %s \" % (Y_pred_rot.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    results=[]\n",
    "    y_true=y_true.flatten()\n",
    "    y_pred=y_pred.flatten()\n",
    "    #Overall precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "    #Per-class precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='macro'))\n",
    "    #jaccard (right average?)\n",
    "    results.append(metrics.jaccard_score(y_true, y_pred, average='macro'))\n",
    "    return results\n",
    "get_scores(Y_test_rot_vec, Y_pred_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    results=[]\n",
    "    y_true=y_true.flatten()\n",
    "    y_pred=y_pred.flatten()\n",
    "    #Overall precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "    #Per-class precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='weighted'))\n",
    "    #jaccard (right average?)\n",
    "    results.append(metrics.jaccard_score(y_true, y_pred, average='weighted'))\n",
    "    return results\n",
    "get_scores(Y_test_rot_vec, Y_pred_rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape back to original dimensions\n",
    "Y_pred_rot_org = np.reshape(Y_pred_rot, [Y_pred_rot.shape[0], 256, 256])\n",
    "print(Y_pred_rot_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_pred_rot_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Y_test_rot[ind])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Y_pred_rot_org[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2]\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=Y_test_rot_vec.flatten(), predictions=Y_pred_rot.flatten()).numpy()\n",
    "\n",
    "# Normalization of Confusion Matrix to the interpretation of which class is being misclassified.\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    " \n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
    "\n",
    "# plot confusion matrix\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
