{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train and test dataset and the UNET model with the appropriate string extension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (13472, 256, 256)\n",
      "Original label shape: (13472, 256, 256)\n",
      "UNET parameters selection: 16F25Dr3WsreA3D\n"
     ]
    }
   ],
   "source": [
    "train_images = np.load(\"./augmented_data_20/images_train.npy\").astype('float32')\n",
    "train_labels = np.load(\"./augmented_data_20/labels_train.npy\")\n",
    "\n",
    "test_images = np.load(\"./augmented_data_20/images_test.npy\").astype('float32')\n",
    "test_labels = np.load(\"./augmented_data_20/labels_test.npy\")\n",
    "\n",
    "print(\"Original image shape: %s\" % (train_images.shape,))\n",
    "print(\"Original label shape: %s\" % (train_labels.shape,))\n",
    "\n",
    "string = '16F25Dr3WsreA3D'  # string indicating the set of parameters to load\n",
    "print(\"UNET parameters selection: \" + string)\n",
    "\n",
    "U_net = tf.keras.models.load_model('U_net_' + string)  # load the UNET\n",
    "\n",
    "file_path = \"U_net_\" + string + \".h5\"  # file to save the weights\n",
    "checkpoint = ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute weights for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06419430096189083 0.9789436333536252 0.956862065684484\n"
     ]
    }
   ],
   "source": [
    "ct0=[]\n",
    "ct1=[]\n",
    "ct2=[]\n",
    "for i in range(0, train_labels.shape[0]):\n",
    "    img = train_labels[i,:,:]\n",
    "    mask = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==0))\n",
    "    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==1))\n",
    "    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==2))\n",
    "    ct0.append(np.sum(mask[:,:,0]))\n",
    "    ct1.append(np.sum(mask[:,:,1]))\n",
    "    ct2.append(np.sum(mask[:,:,2]))\n",
    "sum_all= sum(ct0)+sum(ct1)+sum(ct2)\n",
    "wt0= 1-(sum(ct0)/sum_all)\n",
    "wt1= 1-(sum(ct1)/sum_all)\n",
    "wt2= 1-(sum(ct2)/sum_all)\n",
    "print(wt0, wt1, wt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of input values: {-128.0, 127.0}\n",
      "Normalized range of input values: {0.0, 1.0}\n",
      "Normalized input image shape: (13472, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "def normalize(image):\n",
    "    image = image - np.amin(image)\n",
    "    image = image/np.amax(image)\n",
    "    return image\n",
    "\n",
    "print(\"Range of input values: %s\" % {np.amin(train_images), np.amax(train_images)})\n",
    "\n",
    "for i in range(train_images.shape[0]):\n",
    "    train_images[i] = normalize(train_images[i])\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_images[i] = normalize(test_images[i])\n",
    "    \n",
    "train_images = train_images[..., np.newaxis]\n",
    "test_images = test_images[..., np.newaxis]\n",
    "\n",
    "print(\"Normalized range of input values: %s\" % {np.amin(train_images), np.amax(train_images)})\n",
    "print(\"Normalized input image shape: %s\" % (train_images.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the training labels to categorical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized new label shape: (13472, 65536)\n"
     ]
    }
   ],
   "source": [
    "new_train_labels = np.reshape(train_labels, [train_labels.shape[0], train_labels.shape[1]*train_labels.shape[2]])\n",
    "train_labels = new_train_labels\n",
    "print(\"Vectorized new label shape: %s\" % (train_labels.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = U_net.fit(train_images, train_labels, epochs = 5, validation_split = 0.2, verbose = 1, \n",
    "                    callbacks = callbacks_list, class_weight = [wt0, wt1, wt2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_net.load_weights(file_path)\n",
    "test_labels_pred = U_net.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the U-net: Overall precision, Per-class precision, IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of test labels: %s \\nShape of predicted labels: %s\" % (test_labels.shape, test_labels_pred.shape))\n",
    "new_test_labels = np.reshape(test_labels, [test_labels.shape[0], test_labels.shape[1]*test_labels.shape[2]])\n",
    "print(\"New test labels shape: %s \" % (new_test_labels.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_pred = np.argmax(test_labels_pred, axis=-1)\n",
    "print(\"New predicted labels shape: %s \" % (test_labels_pred.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    results=[]\n",
    "    y_true=y_true.flatten()\n",
    "    y_pred=y_pred.flatten()\n",
    "    #Overall precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "    #Per-class precision\n",
    "    results.append(metrics.precision_score(y_true, y_pred, average='macro'))\n",
    "    #jaccard (right average?)\n",
    "    results.append(metrics.jaccard_score(y_true, y_pred, average='macro'))\n",
    "    return results\n",
    "get_scores(new_test_labels, test_labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot outcome as Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape back to original dimensions\n",
    "test_labels_pred_org = np.reshape(test_labels_pred, [test_labels_pred.shape[0], 256, 256])\n",
    "test_labels_pred_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an example of original label VS predicted label\n",
    "ind = 2\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(labels_test[ind])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(labels_test_pred_org[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2]\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=new_test_labels.flatten(), predictions=test_labels_pred.flatten()).numpy()\n",
    "\n",
    "# Normalization of Confusion Matrix to the interpretation of which class is being misclassified.\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    " \n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
    "\n",
    "# plot confusion matrix\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
